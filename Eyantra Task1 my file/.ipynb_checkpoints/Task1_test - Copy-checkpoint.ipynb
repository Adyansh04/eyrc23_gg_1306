{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28a0ba2-7397-43fd-b667-b3a0803babe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43236a77-1ab7-4948-b3df-f41f26bbd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(task_1a_dataframe):\n",
    "    # Create a copy of the input dataframe\n",
    "    encoded_dataframe = task_1a_dataframe.copy()\n",
    "\n",
    "    # Initialize LabelEncoder for categorical columns\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Encode each categorical column\n",
    "    encoded_dataframe['Education'] = label_encoder.fit_transform(encoded_dataframe['Education'])\n",
    "    encoded_dataframe['City'] = label_encoder.fit_transform(encoded_dataframe['City'])\n",
    "    encoded_dataframe['Gender'] = label_encoder.fit_transform(encoded_dataframe['Gender'])\n",
    "    encoded_dataframe['EverBenched'] = label_encoder.fit_transform(encoded_dataframe['EverBenched'])\n",
    "    encoded_dataframe['PaymentTier'] = label_encoder.fit_transform(encoded_dataframe['PaymentTier'])\n",
    "    encoded_dataframe['ExperienceInCurrentDomain'] = label_encoder.fit_transform(encoded_dataframe['ExperienceInCurrentDomain'])\n",
    "    encoded_dataframe['LeaveOrNot'] = label_encoder.fit_transform(encoded_dataframe['LeaveOrNot'])\n",
    "\n",
    "    # Return the encoded dataframe\n",
    "    return encoded_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea85299-f7c5-4319-a18a-c39b888ca876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features_and_targets(encoded_dataframe):\n",
    "    # Define the features (excluding 'LeaveOrNot' column)\n",
    "    features = encoded_dataframe.drop(columns=['LeaveOrNot'])\n",
    "\n",
    "    # Define the target label as 'LeaveOrNot'\n",
    "    target = encoded_dataframe['LeaveOrNot']\n",
    "\n",
    "    # Create a list with features and target\n",
    "    features_and_targets = [features, target]\n",
    "\n",
    "    return features_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a84b592-43f3-4734-84f1-d2ff5c8db0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_as_tensors(features_and_targets):\n",
    "    # Extract features and target from the input list\n",
    "    features, target = features_and_targets\n",
    "\n",
    "    # Convert features and target to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(target.values, dtype=torch.float32)\n",
    "\n",
    "    # Split the data into training and validation sets (80% training, 20% validation)\n",
    "    split_ratio = 0.8\n",
    "    split_index = int(len(X_train_tensor) * split_ratio)\n",
    "\n",
    "    X_train, X_test = X_train_tensor[:split_index], X_train_tensor[split_index:]\n",
    "    y_train, y_test = y_train_tensor[:split_index], y_train_tensor[split_index:]\n",
    "\n",
    "    # Create PyTorch datasets and data loaders for training and validation\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Return the tensors and iterable dataset for training\n",
    "    tensors_and_iterable_training_data = [X_train, X_test, y_train, y_test, train_loader]\n",
    "\n",
    "    return tensors_and_iterable_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7b4ac76-10dc-4dbd-a00c-246340a755f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "class Salary_Predictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Salary_Predictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def model_loss_function():\n",
    "    return nn.BCEWithLogitsLoss()\n",
    "\n",
    "def model_optimizer(model):\n",
    "    return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def model_number_of_epochs():\n",
    "    return 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f80ac7-c23a-463a-b5bf-3f40d626122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer):\n",
    "\n",
    "\n",
    "    X_train, _, y_train, _ , train_loader = tensors_and_iterable_training_data\n",
    "\n",
    "    for epoch in range(number_of_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = loss_function(outputs, batch_y.unsqueeze(1))  # BCEWithLogitsLoss expects 2D target\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{number_of_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b988c9a6-119a-465c-bf04-07cef307acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
    "\n",
    "    _, X_test, _, y_test, _ = tensors_and_iterable_training_data\n",
    "\n",
    "    trained_model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = trained_model(X_test)\n",
    "        predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct_predictions = (predicted_labels == y_test.unsqueeze(1)).sum().item()\n",
    "        total_samples = len(y_test)\n",
    "        model_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Validation Accuracy: {model_accuracy * 100:.2f}%\")\n",
    "\n",
    "    return model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83ccc4fd-17fb-4013-8d81-22eab6329081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.3607\n",
      "Epoch [2/50], Loss: 0.6923\n",
      "Epoch [3/50], Loss: 0.6960\n",
      "Epoch [4/50], Loss: 0.7633\n",
      "Epoch [5/50], Loss: 0.7078\n",
      "Epoch [6/50], Loss: 0.6873\n",
      "Epoch [7/50], Loss: 0.7234\n",
      "Epoch [8/50], Loss: 0.7717\n",
      "Epoch [9/50], Loss: 0.7399\n",
      "Epoch [10/50], Loss: 0.6556\n",
      "Epoch [11/50], Loss: 0.7391\n",
      "Epoch [12/50], Loss: 0.7321\n",
      "Epoch [13/50], Loss: 0.6541\n",
      "Epoch [14/50], Loss: 0.6994\n",
      "Epoch [15/50], Loss: 0.6676\n",
      "Epoch [16/50], Loss: 0.7044\n",
      "Epoch [17/50], Loss: 0.6579\n",
      "Epoch [18/50], Loss: 0.7184\n",
      "Epoch [19/50], Loss: 0.7101\n",
      "Epoch [20/50], Loss: 0.6784\n",
      "Epoch [21/50], Loss: 0.6460\n",
      "Epoch [22/50], Loss: 0.6470\n",
      "Epoch [23/50], Loss: 0.6451\n",
      "Epoch [24/50], Loss: 0.7791\n",
      "Epoch [25/50], Loss: 0.7964\n",
      "Epoch [26/50], Loss: 0.6785\n",
      "Epoch [27/50], Loss: 0.6632\n",
      "Epoch [28/50], Loss: 0.6425\n",
      "Epoch [29/50], Loss: 0.7968\n",
      "Epoch [30/50], Loss: 0.7360\n",
      "Epoch [31/50], Loss: 0.7293\n",
      "Epoch [32/50], Loss: 0.7590\n",
      "Epoch [33/50], Loss: 0.6550\n",
      "Epoch [34/50], Loss: 0.6470\n",
      "Epoch [35/50], Loss: 0.7109\n",
      "Epoch [36/50], Loss: 0.7708\n",
      "Epoch [37/50], Loss: 0.7318\n",
      "Epoch [38/50], Loss: 0.7082\n",
      "Epoch [39/50], Loss: 0.6556\n",
      "Epoch [40/50], Loss: 0.6484\n",
      "Epoch [41/50], Loss: 0.7801\n",
      "Epoch [42/50], Loss: 0.6500\n",
      "Epoch [43/50], Loss: 0.6427\n",
      "Epoch [44/50], Loss: 0.6735\n",
      "Epoch [45/50], Loss: 0.6455\n",
      "Epoch [46/50], Loss: 0.6478\n",
      "Epoch [47/50], Loss: 0.7037\n",
      "Epoch [48/50], Loss: 0.6556\n",
      "Epoch [49/50], Loss: 0.6872\n",
      "Epoch [50/50], Loss: 0.6473\n",
      "Validation Accuracy: 69.47%\n",
      "Accuracy on the test set = 0.6947141316073355\n"
     ]
    }
   ],
   "source": [
    "\ttask_1a_dataframe = pandas.read_csv('task_1a_dataset.csv')\n",
    "\n",
    "\t# data preprocessing and obtaining encoded data\n",
    "\tencoded_dataframe = data_preprocessing(task_1a_dataframe)\n",
    "\n",
    "\t# selecting required features and targets\n",
    "\tfeatures_and_targets = identify_features_and_targets(encoded_dataframe)\n",
    "\n",
    "\t# obtaining training and validation data tensors and the iterable\n",
    "\t# training data object\n",
    "\ttensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
    "\t\n",
    "\t# model is an instance of the class that defines the architecture of the model\n",
    "\tmodel = Salary_Predictor()\n",
    "\n",
    "\t# obtaining loss function, optimizer and the number of training epochs\n",
    "\tloss_function = model_loss_function()\n",
    "\toptimizer = model_optimizer(model)\n",
    "\tnumber_of_epochs = model_number_of_epochs()\n",
    "\n",
    "\t# training the model\n",
    "\ttrained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data, \n",
    "\t\t\t\t\tloss_function, optimizer)\n",
    "\n",
    "\t# validating and obtaining accuracy\n",
    "\tmodel_accuracy = validation_function(trained_model,tensors_and_iterable_training_data)\n",
    "\tprint(f\"Accuracy on the test set = {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbfa362-33d8-4fad-b954-f05ec651e6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256bb743-b62c-4ad6-8aac-edf2589e962b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_1306",
   "language": "python",
   "name": "gg_1306"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
