{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "160213bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 images belonging to 5 classes.\n",
      "Found 32 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.7775 - accuracy: 0.4375 - val_loss: 0.4034 - val_accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8255 - accuracy: 0.6875 - val_loss: 0.2090 - val_accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3301 - accuracy: 0.8906 - val_loss: 0.1991 - val_accuracy: 0.9375\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.4008 - accuracy: 0.8594 - val_loss: 0.0720 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3286 - accuracy: 0.8203 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3412 - accuracy: 0.8281 - val_loss: 0.0804 - val_accuracy: 0.9688\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2865 - accuracy: 0.9062 - val_loss: 0.1691 - val_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.3110 - accuracy: 0.8516 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.2365 - accuracy: 0.9219 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.1849 - accuracy: 0.9531 - val_loss: 0.1065 - val_accuracy: 0.9688\n",
      "Found 10 images belonging to 5 classes.\n",
      "10/10 [==============================] - 1s 59ms/step\n",
      "Image: combat1.jpeg, Predicted Class: combat\n",
      "Image: combat2.jpeg, Predicted Class: combat\n",
      "Image: building1.jpeg, Predicted Class: combat\n",
      "Image: building2.jpeg, Predicted Class: combat\n",
      "Image: fire1.jpeg, Predicted Class: fire\n",
      "Image: fire2.jpeg, Predicted Class: fire\n",
      "Image: rehab1.jpeg, Predicted Class: combat\n",
      "Image: rehab2.jpeg, Predicted Class: fire\n",
      "Image: military1.jpeg, Predicted Class: combat\n",
      "Image: military2.jpeg, Predicted Class: combat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Define class names and labels\n",
    "class_names = [\"combat\", \"destroyedbuilding\", \"fire\", \"humanitarianaid\", \"militaryvehicles\"]\n",
    "class_labels = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Define image and batch size\n",
    "image_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_data_dir = \"training\"\n",
    "test_data_dir = \"testing\"  # Updated path to the testing folder\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "validation_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "# Build and compile the model\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"alien_attack_model.h5\")\n",
    "\n",
    "# Load the trained model for testing\n",
    "model = keras.models.load_model(\"alien_attack_model.h5\")\n",
    "\n",
    "# Prepare the test data\n",
    "test_data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=1,\n",
    "    class_mode=None,  # Set to None to return images as they are\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = model.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = [class_names[i] for i in np.argmax(test_predictions, axis=1)]\n",
    "\n",
    "# Display the predicted class labels for each test image\n",
    "for i, image_path in enumerate(test_generator.filepaths):\n",
    "    filename = os.path.basename(image_path)  # Extract the filename\n",
    "    class_name = predicted_labels[i]\n",
    "    print(f\"Image: {filename}, Predicted Class: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434ee518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Combat: 80 images\n",
      "Destroyed Building: 80 images\n",
      "Fire: 80 images\n",
      "Humanitarian Aid: 80 images\n",
      "Military Vehicles: 80 images\n",
      "\n",
      "Testing Data:\n",
      "Combat: 2 images\n",
      "Destroyed Building: 2 images\n",
      "Fire: 2 images\n",
      "Humanitarian Aid: 2 images\n",
      "Military Vehicles: 2 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder paths for each class in the training dataset\n",
    "train_combat_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\training\\Combat\"\n",
    "train_destroyedbuilding_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\training\\DestroyedBuildings\"\n",
    "train_fire_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\training\\Fire\"\n",
    "train_humanitarianaid_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\training\\Humanitarian Aid and rehabilitation\"\n",
    "train_militaryvehicles_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\training\\Military vehicles and weapons\"\n",
    "\n",
    "# Define the folder paths for each class in the testing dataset\n",
    "test_combat_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\testing\\combat\"\n",
    "test_destroyedbuilding_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\testing\\destroyedbuilding\"\n",
    "test_fire_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\testing\\fire\"\n",
    "test_humanitarianaid_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\testing\\humanitarianaid\"\n",
    "test_militaryvehicles_dir = r\"C:\\Users\\gupta\\Desktop\\Task 2A\\testing\\militaryvehicles\" \n",
    "\n",
    "\n",
    "# Function to count the number of images in a folder\n",
    "def count_images_in_folder(folder_path):\n",
    "    return len(os.listdir(folder_path))\n",
    "\n",
    "# Count the number of images in each class\n",
    "train_combat_count = count_images_in_folder(train_combat_dir)\n",
    "train_destroyedbuilding_count = count_images_in_folder(train_destroyedbuilding_dir)\n",
    "train_fire_count = count_images_in_folder(train_fire_dir)\n",
    "train_humanitarianaid_count = count_images_in_folder(train_humanitarianaid_dir)\n",
    "train_militaryvehicles_count = count_images_in_folder(train_militaryvehicles_dir)\n",
    "\n",
    "test_combat_count = count_images_in_folder(test_combat_dir)\n",
    "test_destroyedbuilding_count = count_images_in_folder(test_destroyedbuilding_dir)\n",
    "test_fire_count = count_images_in_folder(test_fire_dir)\n",
    "test_humanitarianaid_count = count_images_in_folder(test_humanitarianaid_dir)\n",
    "test_militaryvehicles_count = count_images_in_folder(test_militaryvehicles_dir)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Training Data:\")\n",
    "print(f\"Combat: {train_combat_count} images\")\n",
    "print(f\"Destroyed Building: {train_destroyedbuilding_count} images\")\n",
    "print(f\"Fire: {train_fire_count} images\")\n",
    "print(f\"Humanitarian Aid: {train_humanitarianaid_count} images\")\n",
    "print(f\"Military Vehicles: {train_militaryvehicles_count} images\")\n",
    "\n",
    "print(\"\\nTesting Data:\")\n",
    "print(f\"Combat: {test_combat_count} images\")\n",
    "print(f\"Destroyed Building: {test_destroyedbuilding_count} images\")\n",
    "print(f\"Fire: {test_fire_count} images\")\n",
    "print(f\"Humanitarian Aid: {test_humanitarianaid_count} images\")\n",
    "print(f\"Military Vehicles: {test_militaryvehicles_count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb253e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96082f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82d0678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 images belonging to 5 classes.\n",
      "Found 80 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 2.2004 - accuracy: 0.3250 - val_loss: 1.1160 - val_accuracy: 0.5875\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.2701 - accuracy: 0.5000 - val_loss: 0.8618 - val_accuracy: 0.7000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.9892 - accuracy: 0.6313 - val_loss: 0.7564 - val_accuracy: 0.7750\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.8883 - accuracy: 0.6719 - val_loss: 0.6721 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7230 - accuracy: 0.7250 - val_loss: 0.7085 - val_accuracy: 0.7625\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7108 - accuracy: 0.7125 - val_loss: 0.4985 - val_accuracy: 0.8125\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.6530 - accuracy: 0.7656 - val_loss: 0.5242 - val_accuracy: 0.8375\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.6671 - accuracy: 0.7531 - val_loss: 0.5345 - val_accuracy: 0.8250\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5843 - accuracy: 0.7875 - val_loss: 0.5100 - val_accuracy: 0.8125\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.4737 - accuracy: 0.8375 - val_loss: 0.6230 - val_accuracy: 0.7625\n",
      "Found 10 images belonging to 5 classes.\n",
      "10/10 [==============================] - 1s 43ms/step\n",
      "Image: combat1.jpeg, Predicted Class: combat\n",
      "Image: combat2.jpeg, Predicted Class: combat\n",
      "Image: building1.jpeg, Predicted Class: destroyedbuilding\n",
      "Image: building2.jpeg, Predicted Class: destroyedbuilding\n",
      "Image: fire1.jpeg, Predicted Class: fire\n",
      "Image: fire2.jpeg, Predicted Class: fire\n",
      "Image: rehab1.jpeg, Predicted Class: combat\n",
      "Image: rehab2.jpeg, Predicted Class: humanitarianaid\n",
      "Image: military1.jpeg, Predicted Class: militaryvehicles\n",
      "Image: military2.jpeg, Predicted Class: militaryvehicles\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Define class names and labels\n",
    "class_names = [\"combat\", \"destroyedbuilding\", \"fire\", \"humanitarianaid\", \"militaryvehicles\"]\n",
    "class_labels = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Define image and batch size\n",
    "image_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_data_dir = \"training\"\n",
    "test_data_dir = \"testing\"  # Updated path to the testing folder\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "validation_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "# Build and compile the model\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"alien_attack_model.h5\")\n",
    "\n",
    "# Load the trained model for testing\n",
    "model = keras.models.load_model(\"alien_attack_model.h5\")\n",
    "\n",
    "# Prepare the test data\n",
    "test_data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=1,\n",
    "    class_mode=None,  # Set to None to return images as they are\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = model.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = [class_names[i] for i in np.argmax(test_predictions, axis=1)]\n",
    "\n",
    "# Display the predicted class labels for each test image\n",
    "for i, image_path in enumerate(test_generator.filepaths):\n",
    "    filename = os.path.basename(image_path)  # Extract the filename\n",
    "    class_name = predicted_labels[i]\n",
    "    print(f\"Image: {filename}, Predicted Class: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc213cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7400a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58063c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5c5fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 images belonging to 5 classes.\n",
      "Found 80 images belonging to 5 classes.\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 47s 4s/step - loss: 1.2048 - accuracy: 0.5312 - val_loss: 0.2783 - val_accuracy: 0.9125 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.4350 - accuracy: 0.8344 - val_loss: 0.1595 - val_accuracy: 0.9375 - lr: 9.0484e-04\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.2801 - accuracy: 0.9094 - val_loss: 0.1040 - val_accuracy: 0.9750 - lr: 8.1873e-04\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.2201 - accuracy: 0.9344 - val_loss: 0.1853 - val_accuracy: 0.9500 - lr: 7.4082e-04\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.1425 - accuracy: 0.9500 - val_loss: 0.1634 - val_accuracy: 0.9375 - lr: 6.7032e-04\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 34s 3s/step - loss: 0.1282 - accuracy: 0.9625 - val_loss: 0.1680 - val_accuracy: 0.9500 - lr: 6.0653e-04\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.0984 - accuracy: 0.9719 - val_loss: 0.0801 - val_accuracy: 0.9625 - lr: 5.4881e-04\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.1043 - accuracy: 0.9719 - val_loss: 0.1127 - val_accuracy: 0.9500 - lr: 4.9659e-04\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 33s 3s/step - loss: 0.0887 - accuracy: 0.9812 - val_loss: 0.1664 - val_accuracy: 0.9500 - lr: 4.4933e-04\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 35s 3s/step - loss: 0.0749 - accuracy: 0.9812 - val_loss: 0.1406 - val_accuracy: 0.9625 - lr: 4.0657e-04\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.0782 - accuracy: 0.9781 - val_loss: 0.1198 - val_accuracy: 0.9500 - lr: 3.6788e-04\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.1569 - val_accuracy: 0.9500 - lr: 3.3287e-04\n",
      "Found 10 images belonging to 5 classes.\n",
      "10/10 [==============================] - 6s 199ms/step\n",
      "Image: combat1.jpeg, Predicted Class: combat\n",
      "Image: combat2.jpeg, Predicted Class: combat\n",
      "Image: building1.jpeg, Predicted Class: destroyedbuilding\n",
      "Image: building2.jpeg, Predicted Class: destroyedbuilding\n",
      "Image: fire1.jpeg, Predicted Class: fire\n",
      "Image: fire2.jpeg, Predicted Class: fire\n",
      "Image: rehab1.jpeg, Predicted Class: humanitarianaid\n",
      "Image: rehab2.jpeg, Predicted Class: humanitarianaid\n",
      "Image: military1.jpeg, Predicted Class: militaryvehicles\n",
      "Image: military2.jpeg, Predicted Class: militaryvehicles\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Define class names and labels\n",
    "class_names = [\"combat\", \"destroyedbuilding\", \"fire\", \"humanitarianaid\", \"militaryvehicles\"]\n",
    "class_labels = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Define image and batch size\n",
    "image_size = (224, 224)  # Changed to match DenseNet201 input size\n",
    "batch_size = 32\n",
    "\n",
    "# Data augmentation and preprocessing\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_data_dir = \"training\"\n",
    "test_data_dir = \"testing\"  # Updated path to the testing folder\n",
    "\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "validation_generator = train_data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "# Build and compile the model (DenseNet201)\n",
    "base_model = DenseNet201(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),  # Changed to Global Average Pooling\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "for layer in base_model.layers[-10:]:  # Fine-tuning last few layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Training with a learning rate scheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_scheduler(epoch):\n",
    "    return 0.001 * np.exp(-epoch / 10)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[lr_callback, early_stopping]\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"alien_attack_model.h5\")\n",
    "\n",
    "# Load the trained model for testing\n",
    "model = keras.models.load_model(\"alien_attack_model.h5\")\n",
    "\n",
    "# Prepare the test data\n",
    "test_data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Make predictions on test data\n",
    "test_predictions = model.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = [class_names[i] for i in np.argmax(test_predictions, axis=1)]\n",
    "\n",
    "# Display the predicted class labels for each test image\n",
    "for i, image_path in enumerate(test_generator.filepaths):\n",
    "    filename = os.path.basename(image_path)\n",
    "    class_name = predicted_labels[i]\n",
    "    print(f\"Image: {filename}, Predicted Class: {class_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
